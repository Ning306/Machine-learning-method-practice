{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 支援向量機 (Support Vector Machine, SVM)\n",
    "\n",
    "支援向量機（SVM）是一種強大的監督式學習演算法，主要用於分類和回歸問題。SVM 透過構建一條最佳超平面（Hyperplane）來將不同類別的數據分開，並最大化類別之間的間隔。\n",
    "\n",
    "## 主要特點\n",
    "- **適用於線性和非線性問題**：透過核函數將數據映射到高維空間，處理非線性分類問題。\n",
    "- **對小樣本和高維數據表現良好**：即使在樣本較少的情況下，也能提供良好的泛化能力。\n",
    "- **能夠處理異常值**：透過間隔最大化減少異常值的影響。\n",
    "\n",
    "---\n",
    "\n",
    "## SVM 的工作原理\n",
    "1. **尋找最佳超平面**  \n",
    "   - 將不同類別的數據點分開，並最大化類別之間的「間隔 (Margin)」。\n",
    "   - 超平面的方程式：\n",
    "     \\[\n",
    "     w \\cdot x + b = 0\n",
    "     \\]\n",
    "   - 其中：\n",
    "     - \\( w \\) 是權重向量\n",
    "     - \\( x \\) 是特徵向量\n",
    "     - \\( b \\) 是偏差項\n",
    "\n",
    "2. **支持向量**  \n",
    "   - 與超平面最近的數據點稱為支持向量，這些點決定了最佳分隔邊界。\n",
    "\n",
    "3. **最大化間隔 (Margin Maximization)**  \n",
    "   - SVM 嘗試找到使正、負類別數據點之間的間隔最大化的超平面，間隔定義為：\n",
    "     \\[\n",
    "     \\text{Margin} = \\frac{2}{\\|w\\|}\n",
    "     \\]\n",
    "\n",
    "---\n",
    "\n",
    "## 損失函數（合頁損失 Hinge Loss）\n",
    "SVM 目標是最小化以下損失函數：\n",
    "\n",
    "\\[\n",
    "L(w, b) = \\sum_{i=1}^{n} \\max(0, 1 - y_i (w \\cdot x_i + b)) + \\lambda \\|w\\|^2\n",
    "\\]\n",
    "\n",
    "其中：\n",
    "- \\( y_i \\) 表示真實標籤（+1 或 -1）\n",
    "- \\( \\lambda \\) 是正則化參數，用於控制模型的複雜度\n",
    "\n",
    "---\n",
    "\n",
    "## 核函數 (Kernel Function)\n",
    "當數據線性不可分時，SVM 使用核函數將數據映射到更高維的特徵空間，使其變得可分。常見的核函數包括：\n",
    "\n",
    "1. **線性核 (Linear Kernel)**：\n",
    "   \\[\n",
    "   K(x_i, x_j) = x_i \\cdot x_j\n",
    "   \\]\n",
    "   - 適用於線性可分的數據。\n",
    "\n",
    "2. **多項式核 (Polynomial Kernel)**：\n",
    "   \\[\n",
    "   K(x_i, x_j) = (x_i \\cdot x_j + c)^d\n",
    "   \\]\n",
    "   - 適用於較複雜的數據關係。\n",
    "\n",
    "3. **高斯徑向基核 (RBF Kernel, Radial Basis Function)**：\n",
    "   \\[\n",
    "   K(x_i, x_j) = \\exp\\left(-\\frac{\\|x_i - x_j\\|^2}{2\\sigma^2}\\right)\n",
    "   \\]\n",
    "   - 適用於非線性數據，常用於實際應用中。\n",
    "\n",
    "4. **Sigmoid 核 (Sigmoid Kernel)**：\n",
    "   \\[\n",
    "   K(x_i, x_j) = \\tanh(\\alpha x_i \\cdot x_j + c)\n",
    "   \\]\n",
    "   - 類似於神經網絡的激活函數。\n",
    "\n",
    "---\n",
    "\n",
    "## SVM 的優缺點\n",
    "### 優點\n",
    "- **對高維數據效果良好**：在特徵數遠大於樣本數的情況下，仍能表現良好。\n",
    "- **抗過擬合能力強**：透過正則化參數控制模型複雜度。\n",
    "- **適用於非線性數據**：使用核函數解決複雜的決策邊界。\n",
    "\n",
    "### 缺點\n",
    "- **訓練時間較長**：在大規模數據上訓練時間較慢，尤其是非線性核函數。\n",
    "- **對於噪聲敏感**：當數據中存在重疊時，分類效果可能會下降。\n",
    "- **難以調參**：核函數類型和超參數（如 C 和 γ）需要仔細調整。\n",
    "\n",
    "---\n",
    "\n",
    "## 重要參數\n",
    "- **`C` (正則化參數)**：  \n",
    "  - 控制間隔的大小與錯誤分類的權衡。\n",
    "  - \\( C \\) 越大，分類錯誤懲罰越嚴格，可能過擬合。\n",
    "  - \\( C \\) 越小，容許錯誤較多，可能欠擬合。\n",
    "\n",
    "- **`gamma` (γ, RBF 核的參數)**：  \n",
    "  - 控制影響範圍，γ 值越大，影響範圍越小（更趨於擬合），γ 值越小，影響範圍越大。\n",
    "\n",
    "---\n",
    "\n",
    "## SVM 的應用範圍\n",
    "- **文本分類**：垃圾郵件檢測、情感分析等。\n",
    "- **圖像識別**：手寫數字識別、人臉識別等。\n",
    "- **醫療診斷**：疾病分類、癌症檢測等。\n",
    "- **金融領域**：信用評估、欺詐偵測等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入我之前做以清整過的鐵達尼號資料集\n",
    "data = pd.read_csv('tanic_clearn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.columns[1:]]\n",
    "y = data[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state= 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass         0\n",
       "Sex            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Embarked       0\n",
       "Initial        0\n",
       "Age_band       0\n",
       "Family_Size    0\n",
       "Alone          0\n",
       "Fare_cat       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum() #再次確認資料是已經沒有遺失值的、且可使用的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for linear SVM is 0.8395522388059702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model_linear = svm.SVC(kernel='linear', C=0.1)\n",
    "model_linear.fit(X_train, y_train)\n",
    "pred_linear = model_linear.predict(X_test)\n",
    "accuracy_score_linear = metrics.accuracy_score(pred_linear, y_test)\n",
    "print('Accuracy for linear SVM is', accuracy_score_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for rbf SVM is  0.8582089552238806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#rbf 常用於非線性可分支持向量機，具備良好的性能。\n",
    "model_rbf = svm.SVC(kernel='rbf',C=1,gamma=0.1)\n",
    "model_rbf.fit(X_train,y_train)\n",
    "pred_rbf = model_rbf.predict(X_test)\n",
    "accuracy_score_rbf = metrics.accuracy_score(pred_rbf,y_test)\n",
    "print('Accuracy for rbf SVM is ',accuracy_score_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for rbf SVM is  0.8507462686567164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#poly \n",
    "model_poly = svm.SVC(kernel='poly',C=0.5,gamma='auto')\n",
    "model_poly.fit(X_train,y_train)\n",
    "pred_rbf = model_poly.predict(X_test)\n",
    "accuracy_score_rbf = metrics.accuracy_score(pred_rbf,y_test)\n",
    "print('Accuracy for rbf SVM is ',accuracy_score_rbf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
